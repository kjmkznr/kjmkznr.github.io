<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ただのメモ</title>
    <link>https://kjmkznr.github.io/</link>
    <description>Recent content on ただのメモ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 05 Dec 2015 13:00:00 +0900</lastBuildDate>
    <atom:link href="https://kjmkznr.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Terraform: AWSマルチリージョンな環境を構築してみる</title>
      <link>https://kjmkznr.github.io/post/20151205/terraform-multi-region/</link>
      <pubDate>Sat, 05 Dec 2015 13:00:00 +0900</pubDate>
      
      <guid>https://kjmkznr.github.io/post/20151205/terraform-multi-region/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://qiita.com/advent-calendar/2015/hashicorp&#34;&gt;HashiCorp Advent Calendar 2015&lt;/a&gt;の5日目の担当が空いていたので書いてみました。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;クラウドを利用されているみなさんは、リージョン障害などに備えるために複数のリージョンを利用されているかと思います。
複数のリージョンに展開する際、どのような方法で行ってますでしょうか？&lt;/p&gt;

&lt;p&gt;CloudFormation Stackを複数のリージョンで作ったり、手動でポチポチやったり、SDKやAWSCLIを使ったスクリプトを使ったり&amp;hellip;&lt;/p&gt;

&lt;p&gt;Terraform を使えば簡単に複数のリージョンを統一的に扱うことが出来ます。&lt;/p&gt;

&lt;p&gt;Terraform は複数のプロバイダ(AWSやGCPなど)を一つのテンプレートの中に混在することが出来ます。
また、1種類のプロバイダを複数使用することも出来るため、AWSにマルチリージョンな環境を構築できます。&lt;/p&gt;

&lt;p&gt;AWS謹製のCloudFormationは、S3やRoute53などのグローバルリソースを除き、そのCloudFormation Stackを作成しているリージョンのリソースしか作成することが出来ません。
もちろん、GCPやDigitalOceanなど外部のサービスを利用することも出来ません。&lt;/p&gt;

&lt;p&gt;このあたりは Terraform の強みですね。&lt;/p&gt;

&lt;h2 id=&#34;マルチリージョン基本編:3574440b8aec5afbdd98dd756b561ced&#34;&gt;マルチリージョン基本編&lt;/h2&gt;

&lt;p&gt;まずは基本的な複数のプロバイダの使い方についてです。&lt;/p&gt;

&lt;p&gt;シングルリージョンでAWSを利用する場合は以下のように記述します。
&lt;code&gt;aws_&lt;/code&gt; で始まるリソースは &lt;code&gt;aws&lt;/code&gt; プロバイダが利用されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;aws&amp;quot; {
    region = &amp;quot;ap-northeast-1&amp;quot;
}

resource &amp;quot;aws_instance&amp;quot; &amp;quot;instance-tokyo&amp;quot; {
    instance_type = &amp;quot;t2.micro&amp;quot;
    ami           = &amp;quot;ami-383c1956&amp;quot;
    tag {
        Name = &amp;quot;Tokyo Region&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マルチリージョンで利用したい場合、&lt;code&gt;provider &amp;quot;aws&amp;quot;&lt;/code&gt; を複数書けば良いというわけではありません。
と言ってもそんなに難しいことをやるわけではなく、どちらのプロバイダを利用するのかを識別するために&lt;code&gt;alias&lt;/code&gt;を追加するだけです。&lt;/p&gt;

&lt;p&gt;あとは Resource の定義でどのプロバイダを使用するかを&lt;code&gt;provider&lt;/code&gt;で指定します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;aws&amp;quot; {
    region = &amp;quot;ap-northeast-1&amp;quot;
    alias = &amp;quot;tokyo&amp;quot;
}
provider &amp;quot;aws&amp;quot; {
    region = &amp;quot;ap-southeast-1&amp;quot;
    alias = &amp;quot;singapore&amp;quot;
}

resource &amp;quot;aws_instance&amp;quot; &amp;quot;instance-tokyo&amp;quot; {
    provider      = &amp;quot;aws.tokyo&amp;quot;
    instance_type = &amp;quot;t2.micro&amp;quot;
    ami           = &amp;quot;ami-383c1956&amp;quot;
    tag {
        Name = &amp;quot;Tokyo Region&amp;quot;
    }
}
resource &amp;quot;aws_instance&amp;quot; &amp;quot;instance-singapore&amp;quot; {
    provider      = &amp;quot;aws.singapore&amp;quot;
    instance_type = &amp;quot;t2.micro&amp;quot;
    ami           = &amp;quot;ami-c9b572aa&amp;quot;
    tag {
        Name = &amp;quot;Singapore Region&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;マルチリージョン応用編:3574440b8aec5afbdd98dd756b561ced&#34;&gt;マルチリージョン応用編&lt;/h2&gt;

&lt;p&gt;マルチリージョンにする大きな理由として、冗長性の確保が挙げられると思います。
環境を冗長構成する場合、同じ物をスタンプのように複数のリージョンに展開していくかと思いますが、前述の方法では&lt;code&gt;provider&lt;/code&gt;と&lt;code&gt;ami&lt;/code&gt;だけが違うリソースを大量に定義していかなければならず、非常にめんどくさいですし、修正時に一部のリージョンを変更し忘れるといったオペミスも発生しやすくなります。&lt;/p&gt;

&lt;p&gt;リージョン毎に同じリソースを展開する場合、共通する部分をモジュールとしてまとめてしまうのが簡単です。&lt;/p&gt;

&lt;p&gt;今回サンプルとして作成するテンプレートのディレクトリ構成は以下のようにします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./global.tf
./main.tf
./regional-resource/main.tf
./regional-resource/variables.tf
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モジュール側のリソース定義:3574440b8aec5afbdd98dd756b561ced&#34;&gt;モジュール側のリソース定義&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;./regional-resource/main.tf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;aws&amp;quot; {
    region = &amp;quot;${var.region}&amp;quot;
}

resource &amp;quot;aws_instance&amp;quot; &amp;quot;instance&amp;quot; {
    instance_type               = &amp;quot;t2.micro&amp;quot;
    ami                         = &amp;quot;${lookup(var.ami_id, var.region)}&amp;quot;
    associate_public_ip_address = true
    tag {
        Name = &amp;quot;${var.name}&amp;quot;
    }
}

output &amp;quot;public_ip&amp;quot; {
    value = &amp;quot;${aws_instance.instance.public_ip}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;./regional-resource/variables.tf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;region&amp;quot; {}
variable &amp;quot;name&amp;quot; {}
variable &amp;quot;ami_id&amp;quot; {
    default {
        ap-northeast-1  = &amp;quot;ami-383c1956&amp;quot;
        ap-southeast-1  = &amp;quot;ami-c9b572aa&amp;quot;
        ap-southeast-2  = &amp;quot;ami-48d38c2b&amp;quot;
        us-east-1       = &amp;quot;ami-60b6c60a&amp;quot;
        us-west-1       = &amp;quot;ami-d5ea86b5&amp;quot;
        us-west-2       = &amp;quot;ami-f0091d91&amp;quot;
        eu-west-1       = &amp;quot;ami-bff32ccc&amp;quot;
        eu-central-1    = &amp;quot;ami-bc5b48d0&amp;quot;
        sa-east-1       = &amp;quot;ami-6817af04&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;モジュールを使う側のリソース定義:3574440b8aec5afbdd98dd756b561ced&#34;&gt;モジュールを使う側のリソース定義&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;./main.tf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;module &amp;quot;ap-northeast-1&amp;quot; {
    source = &amp;quot;./regional-resource&amp;quot;

    region   = &amp;quot;ap-northeast-1&amp;quot;
    name     = &amp;quot;Tokyo&amp;quot;
}
module &amp;quot;ap-southeast-1&amp;quot; {
    source = &amp;quot;./regional-resource&amp;quot;

    region   = &amp;quot;ap-southeast-1&amp;quot;
    name     = &amp;quot;Singapore&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;./global.tf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_route53_zone&amp;quot; &amp;quot;primary&amp;quot; {
   name = &amp;quot;example.com&amp;quot;
}

resource &amp;quot;aws_route53_record&amp;quot; &amp;quot;www&amp;quot; {
   zone_id = &amp;quot;${aws_route53_zone.primary.zone_id}&amp;quot;
   name = &amp;quot;www.example.com&amp;quot;
   type = &amp;quot;A&amp;quot;
   ttl = &amp;quot;300&amp;quot;
   records = [
       &amp;quot;${module.ap-northeast-1.public_ip}&amp;quot;,
       &amp;quot;${module.ap-southeast-1.public_ip}&amp;quot;,
   ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;global.tf&lt;/code&gt; ではRoute53にゾーンを作成し、東京都シンガポールのインスタンスのIPアドレスを登録しています。&lt;/p&gt;

&lt;p&gt;以上のテンプレートで出来上がる構成がこんな感じです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kjmkznr.github.io/images/20151205/terraform_multi-region.png&#34; alt=&#34;multi region diagram&#34; /&gt;
&lt;/p&gt;

&lt;h3 id=&#34;provision:3574440b8aec5afbdd98dd756b561ced&#34;&gt;Provision&lt;/h3&gt;

&lt;p&gt;モジュールを使うと、単に &lt;code&gt;terraform apply&lt;/code&gt; とするだけではダメで先に &lt;code&gt;terraform get&lt;/code&gt; を行う必要があります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform get -update=true
$ terraform plan -module-depth=-1
$ terraform apply
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回はローカルファイルシステムにあるモジュールを使いましたが、Gitなどからも取ってくることが出来ます。(&lt;a href=&#34;https://terraform.io/docs/modules/usage.html&#34;&gt;Using Modules&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;まとめ:3574440b8aec5afbdd98dd756b561ced&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;このように、Terraformを使えば簡単にマルチリージョンな環境を手に入れることができます。
マルチリージョンどころかマルチクラウドな環境も、今回よりちょっと大変ではありますが実現できます。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VaultのSSH Secret Backendを使ってみる</title>
      <link>https://kjmkznr.github.io/post/vault-ssh-secret-backend/</link>
      <pubDate>Fri, 23 Oct 2015 01:18:00 +0900</pubDate>
      
      <guid>https://kjmkznr.github.io/post/vault-ssh-secret-backend/</guid>
      <description>

&lt;p&gt;Vault 0.3がリリースされたときにSSHに関する機能が実装されたと言うのを見て気になっていたのですが、なかなか試せずにいたのですが、先日&lt;a href=&#34;http://connpass.com/event/19980/&#34;&gt;HashiCode#2&lt;/a&gt;に参加したので、その勢いで試してみました。&lt;/p&gt;

&lt;p&gt;Vault の SSH Secret Backend はもの凄く大ざっぱに言うとVaultがSSHのパスワードや公開鍵の管理を行ってくれる機能です。&lt;/p&gt;

&lt;h2 id=&#34;使うもの:8d3d31278536bb5d63ba73eca8d91822&#34;&gt;使うもの&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Vault 0.3以上&lt;/li&gt;
&lt;li&gt;OpenSSH&lt;/li&gt;
&lt;li&gt;vault-ssh-helper&lt;/li&gt;
&lt;li&gt;CentOS 7.0

&lt;ul&gt;
&lt;li&gt;ディストリはGentooでも何でも&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ssh-secret-backend:8d3d31278536bb5d63ba73eca8d91822&#34;&gt;SSH Secret Backend&lt;/h2&gt;

&lt;p&gt;まずは Vault について理解を深めるために&lt;a href=&#34;https://vaultproject.io/intro/getting-started/install.html&#34;&gt;Getting Started&lt;/a&gt;を行ってみるとよいと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vault server -dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このように&lt;code&gt;-dev&lt;/code&gt;を付けて起動すると何も考えずに各種機能を試せます。
この dev モードはメモリだけで動作するので、終了すると設定した内容はすべて消えてしまいます。
また、データの seal もされてないので、プロダクション環境では使わないようにしましょう。&lt;/p&gt;

&lt;h3 id=&#34;vault-ssh-helper-のインストール:8d3d31278536bb5d63ba73eca8d91822&#34;&gt;vault-ssh-helper のインストール&lt;/h3&gt;

&lt;p&gt;Vault の操作の前に vault-ssh-helper をインストールする必要があります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/hashicorp/vault-ssh-helper
$ cd vault-ssh-helper
$ make bootstrap
$ make
$ make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に設定ファイルを作ります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo vi /etc/vault-ssh-helper.d/config.hcl
vault_addr=&amp;quot;http://127.0.0.1:8200&amp;quot;
ssh_mount_point=&amp;quot;ssh&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PAMの設定を変更します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo vi /etc/pam.d/sshd
- auth       substack     password-auth
+ auth requisite pam_exec.so quiet expose_authtok log=/tmp/vaultssh.log /usr/local/bin/vault-ssh-helper -config-file=/etc/vault-ssh-helper.d/config.hcl
+ auth optional pam_unix.so no_set_pass use_first_pass nodelay
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後に /etc/ssh/sshd_config の以下の3つを変更しておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ChallengeResponseAuthentication yes
UsePAM yes
PasswordAuthentication no
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;one-time-password-type:8d3d31278536bb5d63ba73eca8d91822&#34;&gt;One Time Password Type&lt;/h3&gt;

&lt;p&gt;それでは dev mode でOTPを試してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export VAULT_ADDR=&#39;http://127.0.0.1:8200&#39;
$ vault mount ssh
Successfully mounted &#39;ssh&#39; at &#39;ssh&#39;!
$ vault write ssh/roles/otp_key_role \
    key_type=otp \
    default_user=centos \
    cidr_list=127.0.0.0/8,192.168.11.0/24
Success! Data written to: ssh/roles/otp_key_role
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上がOTPの設定です。
One-Time-Tokenを作ってみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vault write ssh/creds/otp_key_role ip=127.0.0.1
Key             Value
lease_id        ssh/creds/otp_key_role/ab69a54e-f845-d29a-0627-a3971cacb7b7
lease_duration  2592000
lease_renewable false
key             0c9e7c24-64bb-8c71-3aa4-fdff88b31fde
key_type        otp
port            22
username        centos
ip              127.0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで指定する &lt;code&gt;ip&lt;/code&gt; は前述の&lt;code&gt;cidr_list&lt;/code&gt;の範囲であれば何でも良いです。
出力結果の&lt;code&gt;key&lt;/code&gt;がOTPです。&lt;/p&gt;

&lt;p&gt;試してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh centos@localhost 
Password: 0c9e7c24-64bb-8c71-3aa4-fdff88b31fde
[centos@localhost ~]$ exit
$ ssh centos@localhost
Password: 0c9e7c24-64bb-8c71-3aa4-fdff88b31fde
Password: 
Password: 
Permission denied (publickey,gssapi-keyex,gssapi-with-mic,keyboard-interactive).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このように一度使ってしまったOTPは再度利用できません。&lt;/p&gt;

&lt;p&gt;次に他のユーザでログインできるOTP作ってみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vault write ssh/creds/otp_key_role ip=127.0.0.1 username=vagrant                                                                                                                                                                           
Key             Value
lease_id        ssh/creds/otp_key_role/f49cfd4e-907d-5cf7-1d80-c9fc932b5ad9
lease_duration  2592000
lease_renewable false
key_type        otp
port            22
username        vagrant
ip              127.0.0.1
key             21a90e3b-fe47-4766-af2e-fcb0093c1864
$ ssh vagrant@localhost
Password: 21a90e3b-fe47-4766-af2e-fcb0093c1864
[vagrant@localhost ~]$ 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;毎回 &lt;code&gt;vault write&lt;/code&gt; コマンドでOTPを作るのはめんどくさいという方は &lt;code&gt;vault ssh&lt;/code&gt; と言うコマンドが用意されています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vault ssh -role otp_key_role centos@localhost
OTP for the session is 28535dc6-7b50-af74-b37f-4b6ebedcf50c
[Note: Install &#39;sshpass&#39; to automate typing in OTP]
Password: 28535dc6-7b50-af74-b37f-4b6ebedcf50c
Last login: Thu Oct 22 23:55:06 2015 from localhost
[centos@localhost ~]$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;書いてある通り &lt;code&gt;sshpass&lt;/code&gt; を入れておけばOTPの入力を省略できます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install -y epel-release
$ sudo yum install -y sshpass
$ vault ssh -role otp_key_role centos@localhost
Last login: Thu Oct 22 23:59:23 2015 from localhost
[centos@localhost ~]$
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dynamic-type:8d3d31278536bb5d63ba73eca8d91822&#34;&gt;Dynamic Type&lt;/h3&gt;

&lt;p&gt;Dynamic Typeは公開鍵を使用して認証として利用する方式です。
仕組みとしては、Vault サーバがログイン先のサーバ・ユーザの authorized_keys に一時的に生成した公開鍵をインジェクトするというものです。&lt;/p&gt;

&lt;p&gt;インジェクトするためにSSHを利用するので、あらかじめVaultに追加した秘密鍵で生成した公開鍵を各サーバに登録しておく必要があります。
また、Vault Serverがインジェクトに使用するユーザが sudo が使える権限を付与する必要があります。&lt;/p&gt;

&lt;p&gt;また、今回はパスワード認証を行わないので&lt;code&gt;ChallengeResponseAuthentication&lt;/code&gt;は&lt;code&gt;no&lt;/code&gt;にしておきましょう。&lt;/p&gt;

&lt;p&gt;最初に秘密鍵・公開鍵ペアの作成し秘密鍵をVaultに登録します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[vagrant@localhost ~]$ openssl genrsa -out shared_key.pem 2048                                                                                                                                                                                                                 
Generating RSA private key, 2048 bit long modulus
............................................................+++
.........................+++
e is 65537 (0x10001)
[vagrant@localhost ~]$ vault write ssh/keys/dev_key key=@shared_key.pem
Success! Data written to: ssh/keys/dev_key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;各サーバの sudoers に以下の設定を入れます。
Vault Serverがログインに利用するユーザは &lt;code&gt;vaultadmin&lt;/code&gt; とします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[vagrant@localhost ~]$ ssh-keygen -f shared_key.pem -y | sudo tee -a /home/vaultadmin/.ssh/authorized_keys
[vagrant@localhost ~]$ visudo
vaultadmin   ALL=(ALL)NOPASSWD: ALL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後にDynamic Key Roleを有効化します。
&lt;code&gt;admin_user&lt;/code&gt; は Vault serverがログインに使用するユーザである &lt;code&gt;vaultadmin&lt;/code&gt; を指定します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[vagrant@localhost ~]$ vault write ssh/roles/dynamic_key_role \
    key_type=dynamic \
    key=dev_key \
    admin_user=vaultadmin \
    default_user=centos \
    cidr_list=127.0.0.0/8,192.168.33.0/24
Success! Data written to: ssh/roles/dynamic_key_role
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では、キーペアを作成してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[vagrant@localhost ~]$ vault write ssh/creds/dynamic_key_role ip=127.0.0.1
Key             Value
lease_id        ssh/creds/dynamic_key_role/657543b6-26ee-370c-d67c-bf0965171afd
lease_duration  2592000
lease_renewable true
ip              127.0.0.1
key             -----BEGIN RSA PRIVATE KEY-----
MIICXQIBAAKBgQC1fPQ1wA0eThBxPCu3WwCBWontKrrYaiOXJkjGkPl+fFSBwIP3
7WUzfVrI9oYEeFisRvbsi1NjMeAFpHwC5vGbqGWd8UGUZW5PDyfoPOnj9jsbUd5U
kPz1nZfxKke73WpXShyqtO3nIiF3BU6XbBSJuOuvDCC/P5ZCL/vSYHCjcQIDAQAB
AoGBAKgUVDtfZQbW92VXe4kxL3Oc/TX3p9l72wBGBYpYg6f/z2fnepDnfB1GkAik
P5PuPPk4M8D4e77XVwkCv5MUfVbC52fQjpVktKsdvt4TMx9r3RrIm/xEkxRNJSr1
vYIXcfBzh49s3CwPrMAOXugE0/1lx2dVjovS8BZbv9wBm9vBAkEAzj4j4PWcSMIn
5MPqyQ8cvWAPdOAKIDXStzTBZ3drHTnE1s2AlSVuBMTnDAvIBXHGpy8lTsysHGqk
OxDWhVseGQJBAOFF7jsSdaU9nhoUk+9wmK/iXrTbjJgzRegmBPnVRaZQNurxcv9p
wQqqMTynP0rIBWuun32wyxQJiS4y9jbwqxkCQQDC7rrMqnhv0IsSTxa/uHfqijux
tPv9G8IxBTzzxUxJkEt61zt8PKdy/ISAvzXr53Dinc3+X7chGK5nYW/RFaEpAkB8
2shd/y4rJkqRQ+R2Kd7GZN1+ucxjss9FCoVpfpX6xqyZbLcC7rcqVQezCTMgHFo8
w2zsOedkNKDOdTpXWu5JAkBWsUq1pLv3B7L5ZgGzE3lIzCNJAsrzoyB+VCp3LsxR
XQ4i1krzcUCyh3g58CdN7mS82kkrQ9iGkTkbu7B6JmVZ
-----END RSA PRIVATE KEY-----
key_type        dynamic
port            22
username        centos
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;key&lt;/code&gt;が生成された秘密鍵です。ファイルに保存します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[vagrant@localhost ~]$ vi dynkey.pem
-----BEGIN RSA PRIVATE KEY-----
MIICXQIBAAKBgQC1fPQ1wA0eThBxPCu3WwCBWontKrrYaiOXJkjGkPl+fFSBwIP3
7WUzfVrI9oYEeFisRvbsi1NjMeAFpHwC5vGbqGWd8UGUZW5PDyfoPOnj9jsbUd5U
kPz1nZfxKke73WpXShyqtO3nIiF3BU6XbBSJuOuvDCC/P5ZCL/vSYHCjcQIDAQAB
AoGBAKgUVDtfZQbW92VXe4kxL3Oc/TX3p9l72wBGBYpYg6f/z2fnepDnfB1GkAik
P5PuPPk4M8D4e77XVwkCv5MUfVbC52fQjpVktKsdvt4TMx9r3RrIm/xEkxRNJSr1
vYIXcfBzh49s3CwPrMAOXugE0/1lx2dVjovS8BZbv9wBm9vBAkEAzj4j4PWcSMIn
5MPqyQ8cvWAPdOAKIDXStzTBZ3drHTnE1s2AlSVuBMTnDAvIBXHGpy8lTsysHGqk
OxDWhVseGQJBAOFF7jsSdaU9nhoUk+9wmK/iXrTbjJgzRegmBPnVRaZQNurxcv9p
wQqqMTynP0rIBWuun32wyxQJiS4y9jbwqxkCQQDC7rrMqnhv0IsSTxa/uHfqijux
tPv9G8IxBTzzxUxJkEt61zt8PKdy/ISAvzXr53Dinc3+X7chGK5nYW/RFaEpAkB8
2shd/y4rJkqRQ+R2Kd7GZN1+ucxjss9FCoVpfpX6xqyZbLcC7rcqVQezCTMgHFo8
w2zsOedkNKDOdTpXWu5JAkBWsUq1pLv3B7L5ZgGzE3lIzCNJAsrzoyB+VCp3LsxR
XQ4i1krzcUCyh3g58CdN7mS82kkrQ9iGkTkbu7B6JmVZ
-----END RSA PRIVATE KEY-----
[vagrant@localhost ~]$ chmod 400 dynkey.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;保存した鍵を利用し、ログインしてみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[vagrant@localhost ~]$ ssh -i dynkey.pem centos@localhost
[centos@localhost ~]$ exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こちらはRevokeするか、&lt;code&gt;lease_duration&lt;/code&gt;が経過するまで鍵を使用することが出来ます。
Revokeは次のように行います。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[vagrant@localhost ~]$ vault revoke ssh/creds/dynamic_key_role/657543b6-26ee-370c-d67c-bf0965171afd
Key revoked with ID &#39;ssh/creds/dynamic_key_role/594ac177-f4b2-b840-31ab-4cea0b15e18a&#39;.
[vagrant@localhost ~]$ ssh -i dynkey.pem centos@localhost
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめ:8d3d31278536bb5d63ba73eca8d91822&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;Vaultを利用することでSSHの鍵の管理をVaultに任せてしまうことができるので、各サーバに鍵の展開を行う必要はなくなりそうです。
今回は使ってみることを優先してみましたが、実際に利用する際は&lt;a href=&#34;https://vaultproject.io/docs/auth/index.html&#34;&gt;Auth Backends&lt;/a&gt;や&lt;a href=&#34;https://vaultproject.io/docs/audit/index.html&#34;&gt;Audit Backends&lt;/a&gt;の設定が必要です。&lt;/p&gt;

&lt;h2 id=&#34;参考文献:8d3d31278536bb5d63ba73eca8d91822&#34;&gt;参考文献&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://vaultproject.io/docs/secrets/ssh/index.html&#34;&gt;Secret Backend: SSH - Vault by HashiCorp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Consul, Consul TemplateとPrometheusで行う簡易メトリクス収集</title>
      <link>https://kjmkznr.github.io/post/consul-prometheus/</link>
      <pubDate>Mon, 05 Oct 2015 22:09:00 +0900</pubDate>
      
      <guid>https://kjmkznr.github.io/post/consul-prometheus/</guid>
      <description>

&lt;p&gt;Consulをサービスディスカバリに使い、Consul TemplateでPrometheusの設定ファイルを生成するという構成で、ノードが増加しても自動的にPrometheusの収集対象が増えるような構成を作ってみました。&lt;/p&gt;

&lt;h2 id=&#34;prometheus:b2b2479edabad69dad66d770f3651d14&#34;&gt;Prometheus&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt;はSoundCloudが開発を行っている監視システムです。
Graphiteと違いPrometheusはPull型のアーキテクチャをとっています。Prometheusサーバがexporterと呼ばれる所謂エージェントに値を取りに行く形です。&lt;/p&gt;

&lt;p&gt;Push型に比べれば、Pull型は負荷が集中するので収集できるノード数は少なくなると思います。
ただ、Push型は何らかの理由でメトリクスデータをPushできなくなったときに、検知が困難になるというデメリットもあります。
Pull型であれば取れなかったことが検知でき、その理由も調べることが可能です。&lt;/p&gt;

&lt;p&gt;時系列データストアは自前の物を利用しているようですが、OpenTSDBも利用可能らしいです。
独自のクエリをサポートしており、収集したデータを加工して表示することも出来ます。
グラフ表示機能はPrometheusサーバにも簡易的な物が用意されていますが、 Rails で書かれた PromDash というものを利用するのが良さそうです。
その他、Push型のデータを収集するための pushgateway や、アラートを出すための alertmanager もあります。&lt;/p&gt;

&lt;p&gt;今回は Prometheus Server と node_exporter を利用します。&lt;/p&gt;

&lt;h2 id=&#34;動作環境:b2b2479edabad69dad66d770f3651d14&#34;&gt;動作環境&lt;/h2&gt;

&lt;p&gt;今回は AWS EC2 を使用します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amazon EC2&lt;/li&gt;
&lt;li&gt;Amazon Linux 2015.03.1

&lt;ul&gt;
&lt;li&gt;Prometheus 0.14.0&lt;/li&gt;
&lt;li&gt;node_exporter 0.9.0&lt;/li&gt;
&lt;li&gt;Consul 0.5.2&lt;/li&gt;
&lt;li&gt;Consul Template 0.10.0&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;tags:b2b2479edabad69dad66d770f3651d14&#34;&gt;Tags&lt;/h3&gt;

&lt;p&gt;EC2のタグは以下のようにしておきます。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Node&lt;/th&gt;
&lt;th&gt;Tag&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;server1&lt;/td&gt;
&lt;td&gt;consul-leader: True&lt;/td&gt;
&lt;td&gt;Consul Server, Prometheus Server&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;node1&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Consul Agent, node_exporter&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;node2&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Consul Agent, node_exporter&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;ports:b2b2479edabad69dad66d770f3651d14&#34;&gt;Ports&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Program&lt;/th&gt;
&lt;th&gt;Protocol&lt;/th&gt;
&lt;th&gt;Port&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Prometheus Server&lt;/td&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;9090&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;node_exporter&lt;/td&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;9100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Consul Server&lt;/td&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;8300, 8301, 8400, 8500, 8600&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;UDP&lt;/td&gt;
&lt;td&gt;8600&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Consul Agent&lt;/td&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;8400, 8500&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;UDP&lt;/td&gt;
&lt;td&gt;8600&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;consul-server-と-consul-template-prometheusの設定:b2b2479edabad69dad66d770f3651d14&#34;&gt;Consul Server と Consul template, Prometheusの設定&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://consul.io/&#34;&gt;Consul&lt;/a&gt;はPrometheusに比べれば有名なので説明は割愛。
インストール手順も割愛。&lt;/p&gt;

&lt;p&gt;まずは、ConsulとConsul Templateが起動するようにします。
Consul Serverのアドレスを取得するためにEC2のタグを参照するので、IAM Roleを付けておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
    &amp;quot;Statement&amp;quot;: [
        {
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;ec2:DescribeInstances&amp;quot;
            ],
            &amp;quot;Resource&amp;quot;: [
                &amp;quot;arn:aws:ec2:::*&amp;quot;
            ]
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;consul-server:b2b2479edabad69dad66d770f3651d14&#34;&gt;Consul Server&lt;/h3&gt;

&lt;p&gt;Upstart を使用し Consul Serverを起動させます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/etc/init/consul_server.conf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;description &amp;quot;Consul&amp;quot;

start on runlevel [2345]
stop on runlevel [!2345]

respawn

script
  if [ -f &amp;quot;/etc/service/consul&amp;quot; ]; then
    . /etc/service/consul
  fi

  # Make sure to use all our CPUs, because Consul can block a scheduler thread
  export GOMAXPROCS=`nproc`
  exec /usr/local/bin/consul agent \
   -server \
   -data-dir=&amp;quot;/var/lib/consul/&amp;quot; \
   -bootstrap-expect １ \
   -config-dir=&amp;quot;/etc/consul.d/&amp;quot; \
   ${CONSUL_FLAGS} \
   &amp;gt;&amp;gt;/var/log/consul.log 2&amp;gt;&amp;amp;1
end script
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo initctl start consul_server
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;consul-template:b2b2479edabad69dad66d770f3651d14&#34;&gt;Consul Template&lt;/h3&gt;

&lt;p&gt;Consul templateはConsulのクラスタ情報を元にファイルを生成してくれます。
クラスタに変化があると、ファイルを更新し、指定したコマンドを実行してくれます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/etc/init/consul_template.conf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;description &amp;quot;Consul template&amp;quot;

start on runlevel [2345]
stop on runlevel [!2345]

respawn

script
  exec /usr/local/bin/consul-template \
      -consul 127.0.0.1:8500 \
      -template &amp;quot;/opt/templates/prometheus.ctmpl:/etc/prometheus/prometheus.yml:initctl restart prometheus&amp;quot; &amp;gt;&amp;gt; /var/log/ctemplate.log 2&amp;gt;&amp;amp;1
end script
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo initctl start consul_template
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;prometheus-1:b2b2479edabad69dad66d770f3651d14&#34;&gt;Prometheus&lt;/h3&gt;

&lt;h4 id=&#34;テンプレートの用意:b2b2479edabad69dad66d770f3651d14&#34;&gt;テンプレートの用意&lt;/h4&gt;

&lt;p&gt;Consul TemplateでPrometheusのコンフィグを生成するためテンプレートを用意します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/opt/templates/prometheus.ctmpl&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;global:
  scrape_interval:     1s
  evaluation_interval: 3s

  labels:
    monitor: &#39;web monitor&#39;

scrape_configs:
  - job_name: &#39;prometheus&#39;
    scrape_interval: 10s
    scrape_timeout: 10s
    target_groups:
      - targets: [&#39;localhost:9090&#39;]

  - job_name: &#39;web&#39;
    scrape_interval: 10s
    scrape_timeout: 10s
    target_groups:
      - targets: [{{range service &amp;quot;web&amp;quot;}}&#39;{{.Address}}:9100&#39;,{{end}}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;service名は &lt;code&gt;web&lt;/code&gt; としています。
この値は後述する Consul Agent とあわせる必要があります。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;scrape_interval&lt;/code&gt;は値を取得する間隔を指定します。&lt;/p&gt;

&lt;p&gt;Prometheus には&lt;a href=&#34;http://prometheus.io/docs/operating/configuration/#consul-sd-configurations-consul_sd_config&#34;&gt;Consulと連携する機能&lt;/a&gt;があるようなのですが、イマイチ使い方が判りませんでした。
これが使えれば、Consul Templateは不要かもしれません。&lt;/p&gt;

&lt;h4 id=&#34;prometheusのインストール:b2b2479edabad69dad66d770f3651d14&#34;&gt;Prometheusのインストール&lt;/h4&gt;

&lt;p&gt;ここはまあ、普通に。
Ansible Playbookとかにしておくと良いかもしれません。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo yum install golang git mercurial gcc-c++ epel-release
$ sudo yum install --enablerepo=epel protobuf
$ cd /usr/local/src
$ git clone https://github.com/prometheus/prometheus.git
$ cd prometheus
$ make build
$ sudo useradd -s /bin/false -m prometheus
$ sudo mkdir /etc/prometheus
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初期の設定ファイルがないと起動しないので、作成しておきます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/etc/prometheus/prometheus.yml&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;global:
  scrape_interval:     1s
  evaluation_interval: 3s

  labels:
    monitor: &#39;web monitor&#39;

scrape_configs:
  - job_name: &#39;prometheus&#39;
    scrape_interval: 10s
    scrape_timeout: 10s
    target_groups:
      - targets: [&#39;localhost:9090&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PrometheusもUpstartで起動させます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/etc/init/prometheus.conf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;description &amp;quot;Prometheus&amp;quot;

start on runlevel [2345]
stop on runlevel [!2345]

respawn

script
  /usr/local/src/prometheus/prometheus -config.file=/etc/prometheus/prometheus.yml
end script
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo initctl start prometheus
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;consul-agentの設定とサービスの定義:b2b2479edabad69dad66d770f3651d14&#34;&gt;Consul Agentの設定とサービスの定義&lt;/h2&gt;

&lt;h3 id=&#34;consul-agent:b2b2479edabad69dad66d770f3651d14&#34;&gt;Consul Agent&lt;/h3&gt;

&lt;p&gt;こちらもConsul Serverと同じく Upstart で起動させます。
起動する際に、Consul Serverのアドレスを AWS CLI を使って取得し、クラスタへJoinさせます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/etc/init/consul_agent.conf&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;description &amp;quot;Consul&amp;quot;

start on runlevel [2345]
stop on runlevel [!2345]

respawn

script
  if [ -f &amp;quot;/etc/service/consul&amp;quot; ]; then
    . /etc/service/consul
  fi

  # Make sure to use all our CPUs, because Consul can block a scheduler thread
  export GOMAXPROCS=`nproc`
  JOIN_TO=&amp;quot;$(aws ec2 describe-instances --query &#39;Reservations[].Instances[?State.Name==`running`].PrivateIpAddress&#39; --output text --filters &#39;Name=tag:consul-leader,Values=true&#39;)&amp;quot;

  exec /usr/local/bin/consul agent \
   -data-dir=&amp;quot;/var/lib/consul&amp;quot; \
   -config-dir=&amp;quot;/etc/consul.d&amp;quot; \
   -join ${JOIN_TO} \
   ${CONSUL_FLAGS} \
   &amp;gt;&amp;gt;/var/log/consul.log 2&amp;gt;&amp;amp;1
end script
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ついでにサービスの定義も行います。
Consulは簡易なサービスのチェックも行えるようになっております。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/etc/consul.d/web.json&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;services&amp;quot;:[
    {
      &amp;quot;name&amp;quot;: &amp;quot;Web&amp;quot;,
      &amp;quot;port&amp;quot;: 80,
      &amp;quot;check&amp;quot;: {
        &amp;quot;script&amp;quot;: &amp;quot;curl -s http://localhost/ -o /dev/null&amp;quot;,
        &amp;quot;interval&amp;quot;: &amp;quot;10s&amp;quot;
      },
      &amp;quot;tags&amp;quot;: [&amp;quot;http&amp;quot;]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo initctl start consul_agent
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これらを組み込んだAMIを作っておいて、あとはインスタンスを起動していけば自動的にどんどん監視対象が増えていきます。&lt;/p&gt;

&lt;h2 id=&#34;promdash:b2b2479edabad69dad66d770f3651d14&#34;&gt;PromDash&lt;/h2&gt;

&lt;p&gt;PromDashというダッシュボード的なWebインターフェイスが提供されています。
PromDashはRailsで出来ており、動かすのがめんどうなので、Dockerで動かすのがオススメです。&lt;/p&gt;

&lt;p&gt;PromDash内のデータベースには、PrometheusサーバのURLと表示するグラフに関する情報のみ記録されてるだけなので、Dockerコンテナが消えても、収集したメトリクスは消えません。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker pull prom/promdash
$ docker run -v /tmp/prom:/tmp/prom -e DATABASE_URL=sqlite3:/tmp/prom/file.sqlite3 prom/promdash ./bin/rake db:migrate
$ docker run -d -p 3000:3000 -v /tmp/prom:/tmp/prom -e DATABASE_URL=sqlite3:/tmp/prom/file.sqlite3 prom/promdash
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;所感:b2b2479edabad69dad66d770f3651d14&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;監視を行うのに一通りの機能は揃っていますが、長期的に運用するときにどのような問題が出るか不透明な点はあります。
短期間使ってみた感じでは、短期間のメトリクス収集にはとても有用な感じがしました。
クエリによる値の集計なども簡単にできてよいです。&lt;/p&gt;

&lt;p&gt;プロダクション環境では本格的に使ったわけではありませんが、イベントなどで使うインフラのメトリクス収集に何回か利用しています。&lt;/p&gt;

&lt;p&gt;使い分けとしては、インスタントにメトリクスをとりたい場合は pcp + Vector, 短期間のメトリクス収集には Prometheus, 長期的な監視やメトリクス収集は Zabbix や Sensu + Graphite がよいかなと。&lt;/p&gt;

&lt;p&gt;ほんとはデータの管理とかやりたくないので、Mackerel, Datadog が安くなればいいですね。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
